{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAT281 - Tarea 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD y Gatitos \n",
    "\n",
    "En este ejercicio utilizaremos la descomposición valor singular con tal de comprimir imágenes, si bien hay algoritmos mucho mejores para esto, será un ejercicio muy ilustrativo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recuerdo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La descomposición SVD de una matriz $A$ de tamaño $m \\times n$ posee la siguiente forma \n",
    "$$\n",
    "A = U \\Sigma V^H\n",
    "$$\n",
    "donde $\\Sigma$ es diagonal $m \\times n$, mientras que $U$ y $V$ son matrices unitarias $m \\times m$ and $n \\times n$, respectivamente. Los elementos diagonales de $\\Sigma$ son no-negativos y aquellos valores positivos son llamados **valores singulares** de $A$. Como convención los valores singulares se listan en orden decreciente a lo largo de la diagonal. Las columnas de $U$ y $V$ son llamadas **vectores singulares** izquierdos y derechos respectivamente.\n",
    "\n",
    "PD: Recuerda que $A^H = \\bar{A}^\\top$, es decir, la matriz traspuesta de la matriz conjugada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import svd,diagsvd,norm\n",
    "\n",
    "np.random.seed(42)  # Para reproducibilidad de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo para una matriz de $2 \\times 2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0.1, 0.5], [0.4, 0.8]])\n",
    "u, s, vh = svd(A)\n",
    "print(u)\n",
    "print(s)\n",
    "print(vh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 1\n",
    "\n",
    "(5 puntos)\n",
    "\n",
    "Define la función `svd_validaton` tal que:\n",
    "\n",
    "1. El _input_ sea un arreglo bidimensional `A` de tamaño $m \\times n$.\n",
    "2. Obtenga la descomposición valor singular de `A`.\n",
    "3. Retorne `True` o `False` si es que se cumple la igualdad \n",
    "$$\n",
    "A = \\sum_{l=1}^{\\min(m, n)} \\sigma_l \\; u_l v_l^H,\n",
    "$$\n",
    "donde $\\sigma_l$ corresponden a los valores singulares de $A$, mientras que $u_i$ y $v_j$ a las columnas de $U$ y $V$ respectivamente. Hint: Utiliza `np.allclose` con la tolerancia por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_validation(A):\n",
    "    u, s, vh = svd(A)\n",
    "    suma=0\n",
    "    for l in range(0,min(A.shape)):\n",
    "        suma+= s[l]*(u[:,l].reshape(-1,1))*(vh[l,:].reshape(1,-1))# forma para escribir producto exterior, también ay alternativa documentación\n",
    "    return np.allclose(A,suma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_test = np.random.randint(100, size=(20, 5))\n",
    "svd_validation(A_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometría"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerar una matriz `A` como un operador lineal tiene una interpretación geométrica muy sencilla, transforma una (hyper)-esfera en una (hyper)-elipse. Por ejemplo, consideremos una esfera unitaria en $\\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_circle(circle):\n",
    "    plt.plot(circle[0, :], circle[1, :])\n",
    "    plt.axis('image');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0, 3.5 * np.pi , num=300)\n",
    "l = np.linspace(-1, 1, num=10)\n",
    "z = np.zeros_like(l)\n",
    "circle = np.array(\n",
    "    [\n",
    "        np.concatenate([l, np.cos(t), z]),\n",
    "        np.concatenate([z, np.sin(t), l])\n",
    "    ]\n",
    ")\n",
    "\n",
    "show_circle(circle) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, al utilizar `A` como un operador lineal, es decir $A C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_circle(A @ circle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 2\n",
    "\n",
    "(5 puntos)\n",
    "\n",
    "* Obtén la descomposición SVD de $A$, tal que $A = U \\Sigma V^H$.\n",
    "* Grafica el resultado de aplicar los siguientes operadores lineales a la circunferencia unitaria:\n",
    "    - $U$\n",
    "    - $\\Sigma$\n",
    "    - $V^H$\n",
    "* Explica con tus palabras la transformación de la circunferencia unitaria luego de aplicar los operadores anteriores, ¿Influye en algo que $U$ y $V$ sean unitarias?\n",
    "* ¿Qué relación tienen los operadores anteriores respecto a aplicar el operador lineal $A$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, vh =  svd(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_circle(u @ circle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_circle(diagsvd(s,A.shape[0],A.shape[1]) @ circle) #escribir matrix explicitamente o np.diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_circle(vh @ circle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Respuesta:__ cada una de las aplicaciones corresponde a una rotación, esto esta relacionado con que en $\\mathbb{R}^2$ las transformaciones unitarias son rotaciones o reflexiones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Respuesta:__ El operador $U$ llevaría el circulo a otro espacio a través de rotaciones o reflexiones, preservando la distancia/angulos, luego el operador $\\Sigma$ expandería o comprimiría en la direción de cada eje siendo en esta instancia que se producen cambios en las distancias/angulos de la figura, para al final , a través de $V^H$ volver a rotar/reflectar, sin perturbar distancias/angulos. Se estaría separando la transformación lineal en operaciones que conservan ángulos/distancias y operaciones lineales \"simples\" que cambian las dimensiones de la matriz(son matrices diagonales, en donde es fácil operar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aproximación Rango Menor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen muchas maneras de expresar una matriz como una suma de matrices de menor rango, por ejemplo:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "a & b \\\\\n",
    "c & d \n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "a & 0 \\\\ 0 & 0  \n",
    "\\end{bmatrix}\n",
    "+ \n",
    "\\begin{bmatrix}\n",
    "0 & b \\\\ 0 & 0 \n",
    "\\end{bmatrix}\n",
    "+ \n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\ c & 0 \n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\ 0 & d \n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Cada una de las matrices del lado derecho pueden tener rango a lo más 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el primer ejercicio demostraste que la descomposición SVD $A$ puede ser expresada como una suma de matrices. Sin embargo, cada una de estas matrices tiene rango 1! Esto pues cada una de estas matrices se forma a partir de los productos externos entre los vectores $u_l$ y $v_l$, es decir $u_l v_l^H$.\n",
    "\n",
    "La pregunta natural es:\n",
    "\n",
    "_¿Cómo obtener una buena aproximación de $A$ utilizando matrices de rango muy bajo?_\n",
    "\n",
    "Bueno, aquí va un teorema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Teorema 1:__\n",
    "\n",
    "\n",
    "\n",
    "Sea $A$ matriz de tamaño $m \\times n$. Para cualquier $0 \\le \\ell \\le r = \\text{rank}(A)$, se define la matriz \n",
    "$$\n",
    "A_\\ell = \\sum_{j=1}^{\\ell} \\sigma_j u_j v_j^*,\n",
    "$$\n",
    "utilizando los valores singulares $\\sigma_j$ y los vectores singulares (izquierdos y derechos) $u_j, v_j$ de $A$,  i.e., $A_\\ell$ se compone de la suma de los primeros $\\ell$ términos de la descomposición SVD escrita como una suma de productor externos. Luego, el mínimo de  $\\| A - B \\|_F$ sobre todas las matrices $B$ de tamaño $m \\times n$ y rango no mayor a $\\ell$ se obtiene por $\\| A - A_\\ell \\|_F$ y el mínimo que se alcanza es  $(\\sigma_{\\ell+1}^2 + \\cdots + \\sigma_r^2)^{1/2}$.\n",
    "\n",
    "Recuerda que la norma de Frobenius se define como\n",
    "\n",
    "$$\n",
    "\\| A \\|_F = \\bigg( \\sum_{i, j} |A_{ij}|^2 \\bigg)^{1/2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivaremos el ejercicio utilizando imágenes en escala de grises ya que es muy intuitivo, fácil de ver y se puede considerar que la imagen es una matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizaremos una foto de una de mis gatitas c:\n",
    "cat = Image.open(Path().resolve().parent / \"images\" / \"coyoya.jpg\").convert('L')\n",
    "cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para convertirla en un numpy array basta con:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_np = np.array(cat)\n",
    "print(cat_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 3\n",
    "\n",
    "(10 puntos)\n",
    "\n",
    "Define la función `low_rank_svd_approximation` tal que:\n",
    "\n",
    "* Los inputs sean $A$ (la imagen convertida un `np.array` de dimensión 2) y un valor entero $\\ell$ que represente la cantidad de términos a sumar de la despomposición SVD (respecto al teorema anterior).\n",
    "* Retorne la aproximación $A_\\ell$\n",
    "* Imprima el error de la aproximación utilizando la norma de Frobenius.\n",
    "\n",
    "Luego prueba tu función y observa la imagen con distintos valores de $\\ell$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_rank_svd_approximation(A, l):\n",
    "    u, s, vh = svd(A)\n",
    "    suma=0\n",
    "    for i in range(0,l):\n",
    "        suma+= s[i]*np.outer(u[:,i],vh[i,:])    #(u[:,i].reshape(-1,1))*(vh[i,:].reshape(1,-1))\n",
    "    print(norm(A-suma,'fro'))\n",
    "    return suma    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat10 = low_rank_svd_approximation(cat_np, l=10)\n",
    "plt.imshow(cat10, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat50 = low_rank_svd_approximation(cat_np, l=50)\n",
    "\n",
    "plt.imshow(cat50, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 4\n",
    "\n",
    "(15 puntos)\n",
    "\n",
    "En el ejercicio anterior fijaste un rango máximo y obtuviste la aproximación, sin embargo, en otro contexto, te gustaría fijar una tolerancia de error y obtener la mejor aproximación.\n",
    "\n",
    "Define la función `low_rank_svd_tol_approximation` tal que:\n",
    "\n",
    "* Los inputs sean $A$ (la imagen convertida un `np.array` de dimensión 2) y $\\varepsilon$ (tolerancia relativa) tal que\n",
    "$$\n",
    "\\left(\\frac{\\sigma_{\\ell+1}^2 + \\cdots + \\sigma_r^2}{\\sigma_1^2 + \\cdots + \\sigma_r^2}\\right)^{1/2} \\le \\varepsilon.\n",
    "$$\n",
    "* Imprima $\\ell(\\varepsilon)$, es decir, el mayor rango aproximado de $A$ tal que el error de aproximación sea a lo más $\\varepsilon$.\n",
    "* Retorne la aproximación $A_{\\ell(\\varepsilon)}$\n",
    "\n",
    "Luego prueba tu función y observa la imagen con distintos valores de $\\varepsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_rank_svd_tol_approximation(A, tol):\n",
    "    u, s, vh = svd(A)\n",
    "    rango=min(A.shape)\n",
    "    norma=norm(s)\n",
    "    for l in range(0, rango): \n",
    "        if norm(s[l:])/norma <= tol:\n",
    "            print(l)\n",
    "            return low_rank_svd_approximation(A, l)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_e1 = low_rank_svd_tol_approximation(cat_np, tol=1.e-1)\n",
    "plt.imshow(cat_e1, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_e2 = low_rank_svd_tol_approximation(cat_np, tol=1.e-2)\n",
    "plt.imshow(cat_e2, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 5\n",
    "\n",
    "(5 puntos)\n",
    "\n",
    "Utilizando alguna imagen de tu preferencia utiliza ambas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_img_name = \"negro.jpg\"\n",
    "your_img = Image.open(Path().resolve().parent / \"images\" / your_img_name ).convert('L')\n",
    "your_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_img_np = np.array(your_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_img10 = low_rank_svd_approximation(your_img_np, l=10)\n",
    "plt.imshow(your_img10, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_img50 = low_rank_svd_approximation(your_img_np, l=20)\n",
    "plt.imshow(your_img50, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_img_e1 = low_rank_svd_tol_approximation(your_img_np, tol=1.e-1)\n",
    "plt.imshow(your_img_e1, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_img_e2 = low_rank_svd_tol_approximation(your_img_np, tol=1.e-2)\n",
    "plt.imshow(your_img_e2, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_img10 = low_rank_svd_approximation(your_img_np, l=225)\n",
    "plt.imshow(your_img10, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pregunta:__ ¿Será una manera útil de comprimir imágenes en el disco duro o crees que existen otras formas más eficientes?\n",
    "\n",
    "__Respuesta:__ Puede ser un paso dentro de un proceso más grande, pero por si sola, no sería suficiente. Si bien reduce la distancia en norma, una imagen donde solo hay un color tuvo problemas al ser comprimido por que no hay \"entendimiento\" de la imagen, teniendo en cuenta el posible problema de los repetidos, teniendo en cuenta que partes de la imagen requieren más detalle, y que parte solo poseen ruido,y  además teniendo en cuenta que si se aplicará directamente a cada canal no se tendría en cuenta correlación, entonces tal vez otros metodos que logren mejor \"entendimiento\" de la imagen sean más eficientes. Tal vez aplicarlo en ciertas zonas, para la luminosidad, y tratar el color por separado. Pero de todas formas pareciera no ser tan robusto(por ej: imagen solo negro capta ruido y pierde lo orginal), tal vez hayan métodos que logren resultados, incluso sin entendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COVID-19 en Chile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *¿Cuál es el panorama actual de Chile frente a la pandemia de COVID-19?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 6\n",
    "\n",
    "(25 puntos)\n",
    "\n",
    "Se ha hablado mucho últimamente que Magallanes es una región crítica en cuanto a casos confirmados de COVID-19. Este ejercicio busca constatar a través de los datos aquellas aseveraciones con un indicador siemple pero que parece ser efectivo que bautizaremos como _tasa promedio de casos nuevos_, definida como el promedio de nuevos casos cada cien mil habitantes para un umbral de tiempo determinado.\n",
    "\n",
    "Utiliza el dataframe `covid_comunas` para obtener el dataframe `covid_tasa_promedio_nuevos` que posee las columnas `region`, `comuna`, `promedio_casos_nuevos`, `poblacion` y `tasa_promedio_casos_nuevos` considerando el umbral de tiempo es entre el 1 y 11 de octubre del año 2020.\n",
    "\n",
    "Para ello considera lo siguiente:\n",
    "\n",
    "* No consideres registros que tengan código de comuna nulo.\n",
    "* Rellena todos los registros de casos totales nulos por cero.\n",
    "* Considera utilizar `melt` u otro método similar para apilar las columnas de fechas particulares en solo dos columnas, `fecha` y `casos_totales`.\n",
    "* Define la columna `casos_nuevos` como la diferencia entre dos registros consecutivos para una misma comuna\n",
    "    - No olvides ordenar por fecha\n",
    "    - El primer registro de cada comuna debe ser nulo.\n",
    "    - Considera utilizar el método `transform`.\n",
    "* Filtra por el umbral de tiempo dado.\n",
    "* Agrupa por región-comuna y luego define la columna `promedio_casos_nuevos` como el promedio de la columna `casos_nuevos`.\n",
    "* En caso que hayas _dropeado_ la columna `poblacion` la puedes volver a agregar utilizando `merge` u otro método apropiado. Se asume que la población no cambia durante el tiempo.\n",
    "* Asigna la columna `tasa_promedio_casos_nuevos` como la cantidad promedio de casos nuevos por cada cien mil habitantes.\n",
    "* Ordena el dataframe resultante por `tasa_promedio_casos_nuevos` de manera descendente.\n",
    "\n",
    "Información del dataset: [aquí](https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_comunas = (\n",
    "    pd.read_csv(\"https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto1/Covid-19.csv\")\n",
    "    .rename(columns=lambda x: x.lower().replace(\" \", \"_\"))\n",
    ")\n",
    "covid_comunas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2020-10-01\" \n",
    "end_date = \"2020-10-11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_comunas.dropna(subset=[\"codigo_comuna\"]).drop([\"codigo_region\",\"tasa\"],axis=1).info() #para notar donde hay nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nuevos_casos(s):\n",
    "        n=s.copy()\n",
    "        n.iloc[0]= np.nan\n",
    "        n.iloc[1:]=s.iloc[1:].values-s.iloc[:-1].values\n",
    "        return n \n",
    "\n",
    "covid_tasa_promedio_nuevos = (covid_comunas.dropna(subset=[\"codigo_comuna\"]).drop([\"codigo_region\",\"tasa\"],axis=1)\n",
    "    .fillna(0) #se aplica a todas partes por facilidad teniendo en cuenta que no hay nulls ni en region ni en comuna ni en codigo_comuna\n",
    "    .melt(id_vars=[\"region\",\"comuna\",\"codigo_comuna\",\"poblacion\"], var_name= \"fecha\" , value_name= \"casos_totales\"  )\n",
    "    .sort_values(by=[\"codigo_comuna\",\"fecha\"]) \n",
    "    .assign(casos_nuevos=lambda df: df.groupby(\"comuna\")[\"casos_totales\"].transform(nuevos_casos) )\n",
    "    [lambda df:(start_date <= df[\"fecha\"]) & (df[\"fecha\"]<= end_date)]\n",
    "    .assign(tasa_promedio_casos_nuevos=lambda df: df[\"casos_nuevos\"].mean()/df[\"poblacion\"]*100000 ) \n",
    "    .sort_values(by=\"tasa_promedio_casos_nuevos\",ascending=False)\n",
    "    .drop(columns=[\"fecha\",\"casos_totales\",\"casos_nuevos\"])\n",
    "    .drop_duplicates()\n",
    ")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_tasa_promedio_nuevos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pregunta:__ ¿Qué puedes observar respecto a las comunas que tienen mayor Tasa Promedio de Casos Nuevos?\n",
    "\n",
    "__Respuesta:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 7\n",
    "\n",
    "(15 puntos)\n",
    "\n",
    "¿Hay correlación entre la cantidad de exámenes PCR y los casos confirmados en cada comuna?\n",
    "\n",
    "\n",
    "Información del dataset: [aquí](https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_pcr = (\n",
    "    pd.read_csv(\"https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto7/PCR.csv\")\n",
    "    .rename(columns=lambda x: x.lower().replace(\" \", \"_\"))\n",
    ")\n",
    "covid_pcr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtén el dataframe `covid_pcr_melt` utilizando `covid_pcr` tal que:\n",
    "\n",
    "* Tenga las columnas `region`, `fecha` y `nm_pcr`.\n",
    "* `fecha` sea del tipo `datetime64`.\n",
    "* `nm_pcr` sea el número de PCR realizados y rellena los valores nulos por cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_pcr_melt = (\n",
    "    covid_pcr.drop([\"codigo_region\",\"poblacion\"],axis=1).melt(id_vars=\"region\", var_name= \"fecha\" , value_name= \"nm_pcr\").fillna(0)\n",
    ")\n",
    "covid_pcr_melt[\"fecha\"]=pd.to_datetime(covid_pcr_melt[\"fecha\"],format='%Y-%m-%d')\n",
    "covid_pcr_melt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtén el dataframe `covid_casos_melt` utilizando `covid_casos` tal que:\n",
    "\n",
    "* Tenga las columnas `region`, `fecha` y `casos_totales`.\n",
    "* Rellena los valores nulos con cero.\n",
    "* `fecha` sea del tipo `datetime64`.\n",
    "* `casos_totales` sea la cantidad de casos totales por región y fecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_casos_melt = (\n",
    "    covid_comunas.drop([\"codigo_region\",\"comuna\",\"codigo_comuna\",\"poblacion\",\"tasa\"],axis=1)\n",
    "    .melt(id_vars=\"region\", var_name= \"fecha\" , value_name= \"casos_totales\")\n",
    "    .fillna(0)\n",
    "    .groupby([\"region\",\"fecha\"])\n",
    "    .agg(casos_totales=(\"casos_totales\",\"sum\"))\n",
    "    .reset_index()\n",
    ")\n",
    "covid_casos_melt[\"fecha\"]=pd.to_datetime(covid_casos_melt[\"fecha\"],format='%Y-%m-%d')\n",
    "covid_casos_melt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, obtén la serie `covid_corr_casos_pcr` de la siguiente manera:\n",
    "\n",
    "* Une `covid_pcr_melt` y `covid_casos_melt` a través de _merge_, utilizando la región y la fecha como llave, además conserva todos los registros (tanto derecha como izquierda).\n",
    "* Rellena los números de PCR con el valor cero.\n",
    "* Haz un `ffill` a los casos totales.\n",
    "* Agrupa por región y obtén la correlación entre `nm_pcr` y `casos_totales`.\n",
    "* Ordena los valores ascendentemente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_corr_casos_pcr = (\n",
    "    covid_pcr_melt.merge(covid_casos_melt,how=\"outer\",on=[\"region\",\"fecha\"]) )\n",
    "covid_corr_casos_pcr[\"nm_pcr\"]=covid_corr_casos_pcr[\"nm_pcr\"].fillna(0)\n",
    "covid_corr_casos_pcr[\"casos_totales\"]=covid_corr_casos_pcr[\"casos_totales\"].ffill()\n",
    "covid_corr_casos_pcr= ( covid_corr_casos_pcr.ffill()\n",
    "    .groupby(\"region\")\n",
    "    .apply(lambda df: df[\"nm_pcr\"].corr(df[\"casos_totales\"]))\n",
    "    .sort_values()\n",
    ")\n",
    "\n",
    "covid_corr_casos_pcr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pregunta:__ ¿Qué puedes inferir del análisis anterior? ¿Se condice con tu sentido común?\n",
    "\n",
    "__Respuesta:__ Existe algún grado de correlación, que es más débil o fuerte dependiendo de la región.Uno desearía que la cantidad de examenes pcr realizados fuera de la mano de los casos que hay en cada lugar, pero otros factores pueden afectar, como que tan saturado está la región y que tan fácil se podían obtener más examenes pcr. Sorprende también teniendo en cuenta la centralización en Chile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 8\n",
    "\n",
    "(10 puntos)\n",
    "\n",
    "Propón y responde una pregunta que puedas resolver analizando dos o más conjuntos de datos del repositorio oficial de datos COVID-19 del Ministerio de Ciencia, Tecnología e Innovación de Chile ([link](https://github.com/MinCiencia/Datos-COVID19)).\n",
    "\n",
    "Se evaluará originalidad, análisis de datos, calidad de la pregunta y respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pregunta:__ ¿Cúal es la relación entre cambios en la distribución etaria, el ratio de uso de ventiladores y el nivel de ocupación de residencias sanitarias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importarán las bases de datos a utilizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_residencias = ( \n",
    "    pd.read_csv(\"https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto36/ResidenciasSanitarias_std.csv\")\n",
    "    .rename(columns=lambda x: x.lower().replace(\" \", \"_\"))\n",
    ") \n",
    "covid_residencias[\"fecha\"]=pd.to_datetime(covid_residencias[\"fecha\"],format='%Y-%m-%d')\n",
    "display(covid_residencias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_ventiladores = ( \n",
    "    pd.read_csv(\"https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto20/NumeroVentiladores_T.csv\")\n",
    "    .rename(columns=lambda x: x.lower().replace(\" \", \"_\"))\n",
    "    .rename(columns={\"ventiladores\":\"fecha\"})\n",
    ") \n",
    "covid_ventiladores[\"fecha\"]=pd.to_datetime(covid_ventiladores[\"fecha\"],format='%Y-%m-%d')\n",
    "display(covid_ventiladores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_genero_etario = ( \n",
    "    pd.read_csv(\"https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto16/CasosGeneroEtario_std.csv\")\n",
    "    .rename(columns=lambda x: x.lower().replace(\" \", \"_\"))\n",
    ")\n",
    "covid_genero_etario[\"fecha\"]=pd.to_datetime(covid_genero_etario[\"fecha\"],format='%Y-%m-%d')\n",
    "\n",
    "display(covid_genero_etario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pivotea el dataset covid_etario, y se crea uno nuevo que tenga en cuenta los casos nuevos diarios en el grupo etario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nuevos_casos(s):\n",
    "        n=s.copy()\n",
    "        n.iloc[0]= np.nan\n",
    "        n.iloc[1:]=s.iloc[1:].values-s.iloc[:-1].values\n",
    "        return n \n",
    "\n",
    "covid_etario=(covid_genero_etario\n",
    ".groupby([\"fecha\",\"grupo_de_edad\"])\n",
    ".agg(casos=(\"casos_confirmados\",\"sum\"))\n",
    ".reset_index()\n",
    "# .assign(Total=lambda df: df.groupby(\"fecha\").agg(lambda df: df[]))\n",
    "\n",
    " .pivot(index=[\"fecha\"],columns=\"grupo_de_edad\",values=\"casos\")\n",
    " .reset_index()\n",
    " .assign(total=lambda df: df.iloc[:,1:].sum(axis=1))\n",
    ")\n",
    "display(covid_etario)\n",
    "covid_etario_nuevo = covid_etario.copy()\n",
    "covid_etario_nuevo.iloc[:,1:] = covid_etario.iloc[:,1:].agg(nuevos_casos) \n",
    "\n",
    "display(covid_etario_nuevo )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se pivotea el data set de residencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_residencias_pivot=(covid_residencias.groupby([\"fecha\",\"categoria\"])\n",
    "    .agg(numero=(\"numero\",\"sum\"))\n",
    "    .reset_index()\n",
    "    .pivot(index=[\"fecha\"],columns=\"categoria\",values=\"numero\")\n",
    "    .reset_index()\n",
    "    .loc[lambda df: df[\"cupos totales\"] != 0]\n",
    "    )\n",
    "display(covid_residencias_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se genera el ratio de casos en el grupo de edad respecto al total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_etario_ratio=covid_etario.copy()\n",
    "for i in covid_etario_ratio.columns[1:-1]:\n",
    "    covid_etario_ratio[i]=(covid_etario[i]/covid_etario[\"total\"] *100)\n",
    "display(covid_etario_ratio)\n",
    "\n",
    "covid_etario_nuevo_ratio=covid_etario_nuevo.copy()\n",
    "for i in covid_etario_ratio.columns[1:-1]:\n",
    "    covid_etario_nuevo_ratio[i]=(covid_etario_nuevo[i]/covid_etario_nuevo[\"total\"] *100)\n",
    "display(covid_etario_nuevo_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se obtiene el ratio de ocupación de residencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " covid_ratio_residencias= (covid_residencias_pivot.groupby(\"fecha\")\n",
    "                          .apply(lambda df: (df[\"usuarios en residencia\"]/df[\"cupos totales\"] ).values[0] ).to_frame().reset_index().rename(columns={0:\"ratio_residencias\"})\n",
    ")\n",
    "display(covid_ratio_residencias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se obtiene el ratio de ocupación de ventiladores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_ratio_ventiladores = covid_ventiladores.groupby(\"fecha\").apply(lambda df: (df[\"ocupados\"]/df[\"total\"] ).values[0] ).to_frame().reset_index().rename(columns={0:\"ratio_ventiladores\"})\n",
    "# covid_ventiladores.columns\n",
    "display(covid_ratio_ventiladores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se unen los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_merged_total= covid_ratio_ventiladores.merge(covid_ventiladores.drop(columns=[\"total\",\"disponibles\"],axis=1),how=\"inner\",on=\"fecha\").merge(covid_ratio_residencias,how=\"inner\",on=\"fecha\").merge(covid_etario,on=\"fecha\")\n",
    "\n",
    "covid_merged_nuevos= ( covid_ventiladores.drop(columns=[\"total\",\"disponibles\"],axis=1)\n",
    "                     .merge(covid_ratio_ventiladores,how=\"inner\",on=\"fecha\")\n",
    "                     .merge(covid_ratio_residencias,how=\"inner\",on=\"fecha\")\n",
    "                     .merge(covid_etario_nuevo,on=\"fecha\")\n",
    ")\n",
    "\n",
    "covid_merged_ratio= covid_ratio_ventiladores.merge(covid_ventiladores.drop(columns=[\"total\",\"disponibles\"],axis=1),how=\"inner\",on=\"fecha\").merge(covid_ratio_residencias,how=\"inner\",on=\"fecha\").merge(covid_etario_ratio,on=\"fecha\")\n",
    "\n",
    "covid_merged_nuevo_ratio= ( covid_ventiladores.drop(columns=[\"total\",\"disponibles\"],axis=1)\n",
    "                     .merge(covid_ratio_ventiladores,how=\"inner\",on=\"fecha\")\n",
    "                     .merge(covid_ratio_residencias,how=\"inner\",on=\"fecha\")\n",
    "                     .merge(covid_etario_nuevo_ratio,on=\"fecha\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene la correlación entre columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation=covid_merged_total.corr()\n",
    "correlation_nuevos=covid_merged_nuevos.corr()\n",
    "correlation_ratio=covid_merged_ratio.corr()\n",
    "correlation_nuevo_ratio=covid_merged_nuevo_ratio.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "veamos que pasa con la correlación entre los casos de distintos grupos etarios y la cantidad de ventiladores, el ratio de uso de ventiladores y el ratio de ocupación de residencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(correlation.iloc[0:3].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vemos que no hay variación significativa entre las correlaciones en lo subgrupos y la correlación del total de casos. La correlaciones serían positiva pero no tan fuerte entre el ratio de ocupación de residencias y los casos,  negativa entre la cantidad de casos y la cantidad de ventiladores ocupados, lo mismo para el ratio de ocupación de ventiladores. Pareciera ser que estamos obteniendo información de como han progresado la saturación de residencias/ventiladores con el numero de casos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos como es la correlación entre los casos en distintos grupos etarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(correlation.iloc[3:,3:].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuertemente correlacionados, como se esperaría. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos que pasa si tenemos en cuentas casos nuevos en vez de casos totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(correlation_nuevos.iloc[0:3].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se pierde relación con la ocupación de residencias, pero se mantiene lo demás"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué pasa al tener en cuenta el ratio de los casos en cada grupo etario con respecto al total?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, veamos como el total de casos se relciona con los cambios de distribución etaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(correlation_ratio[\"total\"].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuerte correlación negativa con adultos y positiva con adultos mayores. Es decir a medida que fue evolucionando la infección del covid en Chile, disminuyó la cantidad de adulto infectados respecto al total, pero aumentó la poroprción de jovenes y adulto mayores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(correlation_ratio.iloc[:3].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se identifican tres grupos: jóvenes, adultos y adultos mayores. para jovenes y adultos mayores la ocupación disminuye al aumentar su proporsión respecto al total de casos. Para adultos hay correlación fuertemente positiva sobretodo con respecto a la cantidad de ocupados.\n",
    "Para el caso de la ocupación de residencias, notamos que no hay relación con respecto a infectados niños, si positiva para adultos jovenes,  mediana negativa para adultos y mediana positiva para adultos mayores. Para esto último, puede ser que lo que se esté manifestando es la relación del ratio de residencias con los infectados totales, y no tanto que tanto/como ocupan las residencias sanitarias cada grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(correlation_ratio.iloc[3:,3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al observar la correlación entre las columnas de los ratios, observamos el patrón de tres grupos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora si tenemos en cuenta el ratio de casos nuevos en cada grupo respecto a la cantidad de casos totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(correlation_nuevo_ratio.iloc[:3].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que existe una relación positiva entre el ratio de ventidladores ocupados y la proporción de nuevos infectados adultos respecto al total. Se produce lo inverso para jovenenes, y la relación entre más una mayor cantidad de adultos mayores en los casos nuevos, es baja. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Respuesta:__ Pareciera ser que en las fases en donde hubo una mayor saturación del uso de ventiladores, estuvieron acompañadas de una mayor proporción de adultos contagiada. Especulando, pareciera ser que como la población adulta es una población que esta expuesta al virus al trabajar y mobilizarse(menor medida adultos mayores), padecen la enfermedad(no tanto para jovenes) y son una porción considerable de nuestra población,  influyen de manera importante en la ocupación de los ventiladores, siendo una porción considerable de la población de Chile, que puede ser que ocupe recursos críticos, como a su vez, puede ser que contagie a otros, que los ocuparán. También, es interesante que una mayor/menor poporción decasos nuevos respecto al total, parece no afectar al ratio de ventiladores usados, curioso. \\\n",
    "Para el caso de residencias sanitarias notamos que esta correlacionada con la pobación infectada, no de niños, que es lo esperable.\\\n",
    "Entre ratio de ocupación de ventiladores y de residencias sanitarias pareciera no haber relación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extra__ intento de análisis con datasets por comuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# covid_fallecidos = (\n",
    "#     pd.read_csv(\"https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto14/FallecidosCumulativo_std.csv\")\n",
    "#     .rename(columns=lambda x: x.lower().replace(\" \", \"_\"))\n",
    "#     .dropna()\n",
    "#     .astype({\"fecha\":\"datetime64\"})\n",
    "    \n",
    "# )\n",
    "\n",
    "# covid_fallecidos_comuna = (\n",
    "#     pd.read_csv(\"https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto38/CasosFallecidosPorComuna_std.csv\")\n",
    "#     .rename(columns=lambda x: x.lower().replace(\" \", \"_\"))\n",
    "#     .dropna()\n",
    "#     .astype({\"fecha\":\"datetime64\"})\n",
    "#     .drop([\"region\",\"comuna\"],axis=1)\n",
    "# )\n",
    "# display(covid_fallecidos_comuna)\n",
    "# covid_fallecidos_comuna.info()\n",
    "# covid_movilidad_comuna = (\n",
    "#     pd.read_csv(\"https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto33/IndiceDeMovilidad_std.csv\")\n",
    "#     .rename(columns=lambda x: x.lower().replace(\" \", \"_\"))\n",
    "#     .dropna()\n",
    "#     .astype({\"fecha\":\"datetime64\"})\n",
    "#     .drop([\"region\",\"comuna\"],axis=1)\n",
    "# )\n",
    "# display(covid_movilidad_comuna)\n",
    "# covid_positividad_comuna = (\n",
    "#     pd.read_csv(\"https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto65/PositividadPorComuna_std.csv\")\n",
    "#     .rename(columns=lambda x: x.lower().replace(\" \", \"_\"))\n",
    "#     .dropna()\n",
    "#     .astype({\"fecha\":\"datetime64\"})\n",
    "#     .drop([\"region\",\"comuna\"],axis=1)\n",
    "# )\n",
    "# covid_positividad_comuna.info()\n",
    "# display(covid_positividad_comuna)\n",
    "# covid_BAC_comuna = ( # budqueda activa casos\n",
    "#     pd.read_csv(\"https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto64/BACPorComuna_std.csv\")\n",
    "#     .rename(columns=lambda x: x.lower().replace(\" \", \"_\"))\n",
    "#     .dropna()\n",
    "#     .astype({\"fecha\":\"datetime64\"})\n",
    "#     .drop([\"region\",\"comuna\"],axis=1)\n",
    "# )\n",
    "# display(covid_BAC_comuna)\n",
    "# covid_cuarentena_comuna = ( \n",
    "#     pd.read_csv(\"https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto29/Cuarentenas-Totales.csv\")\n",
    "#     .rename(columns=lambda x: x.lower().replace(\" \", \"_\"))\n",
    "#     .dropna()\n",
    "#      .astype({\"fecha_de_inicio\":\"datetime64\"})\n",
    "#      .astype({\"fecha_de_término\":\"datetime64\"})\n",
    "#     .drop([\"region\",\"n_region\"],axis=1)\n",
    "#     .rename(columns={\"código_cut_comuna\":\"codigo_comuna\"})\n",
    "# ).loc[lambda df: df[\"estado\"]==\"Histórica\"]\n",
    "\n",
    "\n",
    "# display(covid_cuarentena_comuna)\n",
    "# covid_activo_comuna = ( \n",
    "#     pd.read_csv(\"https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto19/CasosActivosPorComuna_std.csv\")\n",
    "#     .rename(columns=lambda x: x.lower().replace(\" \", \"_\"))\n",
    "#     .dropna()\n",
    "#     .astype({\"fecha\":\"datetime64\"})\n",
    "#     .drop([\"region\",\"comuna\"],axis=1)\n",
    "# ) \n",
    "# display(covid_activo_comuna)\n",
    "# covid_activo_comuna.poblacion.min()\n",
    "# covid_cobertura_comuna = ( # budqueda activa casos\n",
    "#     pd.read_csv(\"https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto66/CoberturaPorComuna_std.csv\")\n",
    "#     .rename(columns=lambda x: x.lower().replace(\" \", \"_\"))\n",
    "#     .dropna()\n",
    "#     .astype({\"fecha\":\"datetime64\"})\n",
    "#     .drop([\"region\",\"comuna\"],axis=1)\n",
    "# )\n",
    "# display(covid_cobertura_comuna )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def nuevos_casos(s):\n",
    "#         n=s.copy()\n",
    "#         n.iloc[0]= np.nan\n",
    "#         n.iloc[1:]=s.iloc[1:].values-s.iloc[:-1].values\n",
    "#         return n \n",
    "# #     [lambda df:(start_date <= df[\"fecha\"]) & (df[\"fecha\"]<= end_date)]\n",
    "# #     .assign(casos_nuevos=lambda df: df.groupby(\"comuna\")[\"casos_totales\"].transform(nuevos_casos) )\n",
    "# covid_unido=(\n",
    "# covid_activo_comuna.assign(casos_nuevos=lambda df: df.groupby(\"codigo_comuna\")[\"casos_activos\"].transform(nuevos_casos) )\n",
    "#      .merge(covid_fallecidos_comuna.drop([\"poblacion\",\"codigo_region\"],axis=1),how=\"inner\",on=[\"codigo_comuna\",\"fecha\"])\n",
    "#       .merge(covid_BAC_comuna.drop([\"poblacion\",\"codigo_region\"],axis=1),how=\"inner\",on=[\"codigo_comuna\",\"fecha\"])   \n",
    "#       .merge(covid_cobertura_comuna.drop([\"poblacion\",\"codigo_region\"],axis=1),how=\"inner\",on=[\"codigo_comuna\",\"fecha\"])   \n",
    "# #      .merge(covid_activo_comuna.drop([\"codigo_region\"],axis=1).assign(casos_nuevos=lambda df: df.groupby(\"codigo_comuna\")[\"casos_activos\"].transform(nuevos_casos) ).drop([\"poblacion\"],axis=1)    ,how=\"outer\",on=[\"codigo_comuna\",\"fecha\"]) \n",
    "# #     .merge(covid_movilidad_comuna.drop([\"poblacion\",\"codigo_region\"],axis=1).loc[lambda df: df[\"variable\"]==\"IM\"].rename(columns={\"value\":\"IM\"}),how=\"inner\",on=[\"codigo_comuna\",\"fecha\"])     \n",
    "# #      .merge(covid_movilidad_comuna.drop([\"poblacion\",\"codigo_region\"],axis=1).loc[lambda df: df[\"variable\"]==\"IM_interno\"].rename(columns={\"value\":\"IM_interno\"}),how=\"inner\",on=[\"codigo_comuna\",\"fecha\"]) \n",
    "# #      .merge(covid_movilidad_comuna.drop([\"poblacion\",\"codigo_region\"],axis=1).loc[lambda df: df[\"variable\"]==\"IM_externo\"].rename(columns={\"value\":\"IM_externo\"}),how=\"inner\",on=[\"codigo_comuna\",\"fecha\"]) \n",
    "# #     .merge(covid_cuarentena_comuna.drop([\"id\",\"nombre\",\"estado\",\"alcance\",\"detalle\"],axis=1) , how=\"outer\", on=\"codigo_comuna\" )\n",
    "#     .assign(tasa=lambda df: df[\"casos_nuevos\"]/df[\"poblacion\"]*100000 )\n",
    "# )\n",
    "# # covid_positividad_comuna.ffill()\n",
    "# print(covid_unido[\"poblacion\"].min())\n",
    "# poblacion = pd.qcut(covid_unido[\"poblacion\"], 10)\n",
    "# grupo= (covid_unido.groupby(poblacion)\n",
    "#      .apply(lambda df: df[\"cobertura_testeo\"].corr(df[\"bac\"])) #efectos cuarentena?\n",
    "# )   \n",
    "# display(grupo)\n",
    "# identidad= lambda x:  x\n",
    "# bins_dt = pd.date_range('2020-08-23', freq='W', periods=10)\n",
    "# cycle = pd.cut(covid_unido[\"fecha\"], bins_dt)\n",
    "# display(cycle)\n",
    "# # aaa=covid_unido.groupby([cycle, 'codigo_comuna']).agg({\"IM_interno\":\"mean\",\"tasa\":\"mean\"}).reset_index()\n",
    "\n",
    "# bins_dt = pd.date_range('2020-08-23', freq='W', periods=6)\n",
    "# cycle = pd.cut(covid_BAC_comuna[\"fecha\"], bins_dt)\n",
    "# display(cycle)\n",
    "# bbb=covid_BAC_comuna.groupby([cycle, 'codigo_comuna']).agg({\"bac\":\"mean\"}).reset_index()\n",
    "\n",
    "# # bins_dt = pd.date_range('2020-08-23', freq='W', periods=10)\n",
    "# # cycle = pd.cut(covid_positividad_comuna[\"fecha\"], bins_dt)\n",
    "# # display(cycle)\n",
    "# # aaa=covid_positividad_comuna.groupby([cycle, 'codigo_comuna']).agg({\"positividad\":\"mean\"}).reset_index()\n",
    "# display(covid_unido.groupby(\"fecha\").apply(lambda df: df[\"tasa\"].corr(df[\"cobertura_testeo\"])) )\n",
    "\n",
    "# display(grupo)\n",
    "\n",
    "# display(covid_unido)\n",
    "# covid_unido.describe()\n",
    "# # covid_unido.plot()\n",
    "# corr=lambda df:( (df[\"bac\"]).corr(df[\"cobertura_testeo\"]) )\n",
    "# corr(covid_unido)\n",
    "# # covid_fallecidos.groupby(\"region\").apply(lambda df: df.plot(x=\"fecha\",y=\"total\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 9\n",
    "\n",
    "(10 puntos)\n",
    "\n",
    "Propón y responde una pregunta que puedas resolver analizando dos o más conjuntos de datos del repositorio oficial de datos COVID-19 del Ministerio de Ciencia, Tecnología e Innovación de Chile ([link](https://github.com/MinCiencia/Datos-COVID19)). Sin utilizar ninguno de los datasets que hayas utilizado en el ejercicio 8.\n",
    "\n",
    "Se evaluará originalidad, análisis de datos, calidad de la pregunta y respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pregunta:__ ¿Cómo se relacionan el ratio de camas ocupadas y la positividad de los test PCR nivel regional a lo largo del tiempo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importaremos primero los datasets correspondientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_positividad_region = (\n",
    "    pd.read_csv(\"https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto55/Positividad_por_region.csv\")\n",
    "    .rename(columns=lambda x: x.lower().replace(\" \", \"_\"))\n",
    "    .dropna()\n",
    "    .drop([\"region_residencia\",\"region\"],axis=1)\n",
    ")\n",
    "covid_positividad_region[\"fecha\"]=pd.to_datetime(covid_positividad_region[\"fecha\"],format='%Y-%m-%d')\n",
    "display(covid_positividad_region)\n",
    "\n",
    "covid_camas_region = (\n",
    "    pd.read_csv(\"https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto58/Camas_UCI_diarias_std.csv\")\n",
    "    .rename(columns=lambda x: x.lower().replace(\" \", \"_\"))\n",
    "    .dropna()\n",
    "    .rename(columns={\"region\":\"codigo_region\"})\n",
    ")\n",
    "\n",
    "covid_camas_region[\"fecha\"]=pd.to_datetime(covid_camas_region[\"fecha\"],format='%Y-%m-%d')\n",
    "\n",
    "display(covid_camas_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cambia la columna de regiones por nombre a una de regiones por número"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_camas_region.replace({'Arica y Parinacota':15, 'Tarapacá':1, 'Antofagasta':2, 'Atacama' :3,'Coquimbo':4,\n",
    " 'Valparaíso':5, 'Metropolitana':13, 'O’Higgins':6, 'Maule':7, 'Ñuble':16, 'Biobío':8,\n",
    " 'Araucanía':9, 'Los Ríos':14, 'Los Lagos' :10,'Aysén':11, 'Magallanes':12},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene el número de camas UCI ocupadas , respecto al total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_ratio_camas=(covid_camas_region.pivot(index=[\"codigo_region\",\"fecha\"],columns=\"serie\",values=\"casos\")\n",
    "                   .reset_index()\n",
    "                   .groupby([\"codigo_region\",\"fecha\"])\n",
    "                   .apply(lambda df:df[\"Camas UCI ocupadas\"]/df[\"Camas UCI habilitadas\"])\n",
    "                   .reset_index().rename(columns={0:\"ratio_camas\"}).drop(\"level_2\",axis=1) )\n",
    "display(covid_ratio_camas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se juntan las tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_merged=covid_positividad_region.merge(covid_ratio_camas, how=\"inner\", on=[\"codigo_region\",\"fecha\"]) \n",
    "display(covid_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene correlación entre las variables en cada instante de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_corr_tiempo=covid_merged.groupby(\"fecha\").apply(lambda df: df[\"positividad\"].corr(df[\"ratio_camas\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se gráfica para tener una idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_corr_tiempo.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(parecen acciones jeje)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se agrupan datos para tener una idea que pasa por región:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cajitas = pd.date_range('2020-02-16', freq='SM', periods=16)\n",
    "grupos = pd.cut(covid_merged[\"fecha\"], cajitas)\n",
    "corr_agrupado=covid_merged.groupby([grupos, 'codigo_region']).apply(lambda df: df[\"positividad\"].corr(df[\"ratio_camas\"])).reset_index().rename(columns={0:\"correlacion_smensual\"}).pivot(index=[\"fecha\"],columns=\"codigo_region\",values=\"correlacion_smensual\").reset_index().drop(index=0)\n",
    "display(corr_agrupado)\n",
    "# display(corr_agrupado.corr() )  #descomente para obtener una idea de la relación(por métodos cuestionables)\n",
    "# for i in corr_agrupado.columns[1:]:\n",
    "#     corr_agrupado[i].plot(x=\"fecha\",y=0) #sad, si quiere ignore esto :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pareciera que cada región sigue su camino, y al agrupar se nota el patrón "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene una correlación en la positividad y el ratio de camas para comparar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=lambda df:( (df[\"positividad\"]).corr(df[\"ratio_camas\"]) )\n",
    "corr(covid_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Respuesta:__ Notamos que la correlación de todos lo datos no representa la situación completa. Notamos que en un intervalo de tiempo existión una correlación fuerte entre la positividad de los examenes PCR y la ocupación de camas, teniendo que ambas medidas de \"saturación\" estaban relacionadas a lo largo de Chile. LLuego, pasamos a una fase en que la correlación desaparece, la curva que se muestra puede estar relacionado a que pasamos de un colapso practicamente a nivel nacional, a aora a situaciones acotadas a cierta zonas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
